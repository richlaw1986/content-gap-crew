# -*- coding: utf-8 -*-
"""Content Gap for AEO and SEO agent

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1dsDngYzt52fcUHeRuVC98huNiDk-sykZ
"""

# ============================================================
# CrewAI: Sanity.io Content Gap Discovery Crew v2
# Focus: NEW CONTENT GAPS (not optimization), AI+CMS topics,
#        Competitor analysis, BigQuery LLM visit data
# ============================================================

!pip install crewai
!pip install --upgrade pydantic>=2.0
!pip install praw
!pip install google-ads
!pip install google-auth google-api-python-client
!pip install beautifulsoup4
!pip install nest_asyncio
!pip install mcp
!pip install langchain-anthropic langchain-openai langchain-google-genai
!pip install google-cloud-bigquery

import os
import json
import re
import xml.etree.ElementTree as ET
from datetime import datetime, timedelta
from typing import Optional, List
import requests
import time

from crewai import Agent, Task, Crew, Process
from crewai.tools import tool
from dotenv import load_dotenv
load_dotenv(override=True)

# ============================================================
# Configuration - Credentials Dictionary
# ============================================================

credentials = {
    'anthropic': {
        'api_key': os.getenv('ANTHROPIC_API_KEY', ''),
    },
    'google_ads': {
        'developer_token': os.getenv('GOOGLE_ADS_DEVELOPER_TOKEN', 'YOUR_DEVELOPER_TOKEN'),
        'client_id': os.getenv('GOOGLE_ADS_CLIENT_ID', 'YOUR_CLIENT_ID'),
        'client_secret': os.getenv('GOOGLE_ADS_CLIENT_SECRET', 'YOUR_CLIENT_SECRET'),
        'refresh_token': os.getenv('GOOGLE_ADS_REFRESH_TOKEN', 'YOUR_REFRESH_TOKEN'),
        'customer_id': os.getenv('GOOGLE_ADS_CUSTOMER_ID', 'YOUR_CUSTOMER_ID'),
    },
    'gsc': {
        'key_file': '/content/fair-ceiling-374017-333574f87cac.json',
        'site_url': 'https://www.sanity.io/',
    },
    'bigquery': {
        'credentials_file': '/content/sanity_bigquery_auth.json',
        'tables': {
            'sanity_llm_visits': 'data-platform-302218.searchconsole.llm-visits2',
            'enterprisecms_llm_logs': 'indexing-api-471516.enterprisecms.llm-logs',
            'headlesscms_llm_logs': 'indexing-api-471516.headlesscms.llm-logs',
        }
    },
    'openai': {
        'api_key': os.getenv('OPENAI_API_KEY', ''),
    },
    'reddit': {
        'client_id': os.getenv('REDDIT_CLIENT_ID', ''),
        'client_secret': os.getenv('REDDIT_CLIENT_SECRET', ''),
        'user_agent': os.getenv('REDDIT_USER_AGENT', 'SanityContentGapBot/1.0'),
    }
}

# GSC API constants
GSC_API_SERVICE_NAME = "webmasters"
GSC_API_VERSION = "v3"
GSC_SCOPE = ["https://www.googleapis.com/auth/webmasters.readonly"]


# ============================================================
# BigQuery Tools - NEW
# ============================================================

@tool
def bigquery_describe_table(table_name: str) -> str:
    """
    Describe the schema of a BigQuery table to understand its structure before querying.
    Available tables:
    - 'sanity_llm_visits': Sanity.io LLM visit logs
    - 'enterprisecms_llm_logs': enterprisecms.org visit logs
    - 'headlesscms_llm_logs': headlesscms.guides visit logs

    Returns column names, types, and sample data to help construct effective queries.
    """
    try:
        from google.cloud import bigquery
    except ImportError:
        return "ERROR: google-cloud-bigquery package required. Install with: pip install google-cloud-bigquery"

    bq_config = credentials['bigquery']
    table_mapping = bq_config['tables']

    # Map friendly names to full table IDs
    if table_name in table_mapping:
        full_table_id = table_mapping[table_name]
    elif table_name in table_mapping.values():
        full_table_id = table_name
    else:
        return f"""ERROR: Unknown table '{table_name}'.
Available tables:
- 'sanity_llm_visits' -> {table_mapping['sanity_llm_visits']}
- 'enterprisecms_llm_logs' -> {table_mapping['enterprisecms_llm_logs']}
- 'headlesscms_llm_logs' -> {table_mapping['headlesscms_llm_logs']}"""

    try:
        os.environ["GOOGLE_APPLICATION_CREDENTIALS"] = bq_config['credentials_file']
        client = bigquery.Client()

        table = client.get_table(full_table_id)

        result = f"""
BIGQUERY TABLE SCHEMA
=====================
Table: {full_table_id}
Created: {table.created}
Modified: {table.modified}
Rows: {table.num_rows:,} (approximate)
Size: {table.num_bytes / (1024*1024):.2f} MB

COLUMNS:
"""
        for field in table.schema:
            result += f"  - {field.name}: {field.field_type}"
            if field.mode == 'REPEATED':
                result += " (ARRAY)"
            if field.description:
                result += f" -- {field.description}"
            result += "\n"

        # Get sample data
        sample_query = f"SELECT * FROM `{full_table_id}` LIMIT 5"
        sample_df = client.query(sample_query).to_dataframe()

        result += f"\nSAMPLE DATA (first 5 rows):\n"
        result += sample_df.to_string(max_colwidth=50)

        # Get date range if there's a timestamp column
        date_columns = [f.name for f in table.schema if 'date' in f.name.lower() or 'time' in f.name.lower() or 'timestamp' in f.name.lower()]
        if date_columns:
            date_col = date_columns[0]
            range_query = f"SELECT MIN({date_col}) as min_date, MAX({date_col}) as max_date FROM `{full_table_id}`"
            range_df = client.query(range_query).to_dataframe()
            result += f"\n\nDATE RANGE ({date_col}): {range_df['min_date'].iloc[0]} to {range_df['max_date'].iloc[0]}"

        return result

    except Exception as e:
        import traceback
        traceback.print_exc()
        return f"ERROR describing table: {str(e)}"


@tool
def bigquery_llm_visits(query_type: str, days: int = 30, limit: int = 100) -> str:
    """
    Query BigQuery for LLM visit data across Sanity-owned properties.

    query_type options:
    - 'top_pages': Most visited pages by LLM bots
    - 'top_pages_sanity': Top pages on sanity.io visited by LLMs
    - 'top_pages_enterprisecms': Top pages on enterprisecms.org
    - 'top_pages_headlesscms': Top pages on headlesscms.guides
    - 'trending': Pages with increasing LLM traffic
    - 'by_bot': Breakdown by LLM bot type (ChatGPT, Claude, Perplexity, etc.)
    - 'content_gaps': Pages competitors have that get LLM traffic but Sanity doesn't

    days: Number of days to look back (default 30)
    limit: Number of results to return (default 100)
    """
    try:
        from google.cloud import bigquery
    except ImportError:
        return "ERROR: google-cloud-bigquery package required. Install with: pip install google-cloud-bigquery"

    bq_config = credentials['bigquery']

    try:
        os.environ["GOOGLE_APPLICATION_CREDENTIALS"] = bq_config['credentials_file']
        client = bigquery.Client()

        # Build query based on type
        sanity_table = bq_config['tables']['sanity_llm_visits']
        enterprise_table = bq_config['tables']['enterprisecms_llm_logs']
        headless_table = bq_config['tables']['headlesscms_llm_logs']

        if query_type == 'top_pages_sanity':
            query = f"""
            SELECT
                page_path,
                COUNT(*) as visits,
                COUNT(DISTINCT DATE(timestamp)) as days_with_visits
            FROM `{sanity_table}`
            WHERE timestamp >= TIMESTAMP_SUB(CURRENT_TIMESTAMP(), INTERVAL {days} DAY)
            GROUP BY page_path
            ORDER BY visits DESC
            LIMIT {limit}
            """

        elif query_type == 'top_pages_enterprisecms':
            query = f"""
            SELECT
                page_path,
                COUNT(*) as visits,
                COUNT(DISTINCT DATE(timestamp)) as days_with_visits
            FROM `{enterprise_table}`
            WHERE timestamp >= TIMESTAMP_SUB(CURRENT_TIMESTAMP(), INTERVAL {days} DAY)
            GROUP BY page_path
            ORDER BY visits DESC
            LIMIT {limit}
            """

        elif query_type == 'top_pages_headlesscms':
            query = f"""
            SELECT
                page_path,
                COUNT(*) as visits,
                COUNT(DISTINCT DATE(timestamp)) as days_with_visits
            FROM `{headless_table}`
            WHERE timestamp >= TIMESTAMP_SUB(CURRENT_TIMESTAMP(), INTERVAL {days} DAY)
            GROUP BY page_path
            ORDER BY visits DESC
            LIMIT {limit}
            """

        elif query_type == 'top_pages':
            # Union across all tables
            query = f"""
            WITH all_visits AS (
                SELECT 'sanity.io' as site, page_path, timestamp FROM `{sanity_table}`
                UNION ALL
                SELECT 'enterprisecms.org' as site, page_path, timestamp FROM `{enterprise_table}`
                UNION ALL
                SELECT 'headlesscms.guides' as site, page_path, timestamp FROM `{headless_table}`
            )
            SELECT
                site,
                page_path,
                COUNT(*) as visits
            FROM all_visits
            WHERE timestamp >= TIMESTAMP_SUB(CURRENT_TIMESTAMP(), INTERVAL {days} DAY)
            GROUP BY site, page_path
            ORDER BY visits DESC
            LIMIT {limit}
            """

        elif query_type == 'by_bot':
            # Assumes there's a user_agent or bot column
            query = f"""
            SELECT
                CASE
                    WHEN LOWER(user_agent) LIKE '%chatgpt%' OR LOWER(user_agent) LIKE '%openai%' THEN 'ChatGPT/OpenAI'
                    WHEN LOWER(user_agent) LIKE '%claude%' OR LOWER(user_agent) LIKE '%anthropic%' THEN 'Claude/Anthropic'
                    WHEN LOWER(user_agent) LIKE '%perplexity%' THEN 'Perplexity'
                    WHEN LOWER(user_agent) LIKE '%google%' OR LOWER(user_agent) LIKE '%bard%' THEN 'Google/Bard'
                    WHEN LOWER(user_agent) LIKE '%bing%' OR LOWER(user_agent) LIKE '%copilot%' THEN 'Bing/Copilot'
                    ELSE 'Other LLM'
                END as bot_type,
                COUNT(*) as visits,
                COUNT(DISTINCT page_path) as unique_pages
            FROM `{sanity_table}`
            WHERE timestamp >= TIMESTAMP_SUB(CURRENT_TIMESTAMP(), INTERVAL {days} DAY)
            GROUP BY bot_type
            ORDER BY visits DESC
            """

        elif query_type == 'trending':
            # Compare recent week to previous weeks
            query = f"""
            WITH weekly_visits AS (
                SELECT
                    page_path,
                    COUNTIF(timestamp >= TIMESTAMP_SUB(CURRENT_TIMESTAMP(), INTERVAL 7 DAY)) as recent_week,
                    COUNTIF(timestamp < TIMESTAMP_SUB(CURRENT_TIMESTAMP(), INTERVAL 7 DAY)
                        AND timestamp >= TIMESTAMP_SUB(CURRENT_TIMESTAMP(), INTERVAL {days} DAY)) as previous_period
                FROM `{sanity_table}`
                WHERE timestamp >= TIMESTAMP_SUB(CURRENT_TIMESTAMP(), INTERVAL {days} DAY)
                GROUP BY page_path
            )
            SELECT
                page_path,
                recent_week,
                previous_period,
                SAFE_DIVIDE(recent_week, NULLIF(previous_period / {(days-7)/7:.1f}, 0)) as growth_rate
            FROM weekly_visits
            WHERE recent_week > 5
            ORDER BY growth_rate DESC
            LIMIT {limit}
            """

        elif query_type == 'content_gaps':
            # Pages on competitor sites getting traffic that Sanity doesn't have
            query = f"""
            WITH competitor_topics AS (
                SELECT
                    REGEXP_EXTRACT(page_path, r'/([^/]+)/?$') as topic_slug,
                    page_path,
                    COUNT(*) as visits
                FROM `{enterprise_table}`
                WHERE timestamp >= TIMESTAMP_SUB(CURRENT_TIMESTAMP(), INTERVAL {days} DAY)
                GROUP BY topic_slug, page_path
                HAVING visits > 3
            ),
            sanity_topics AS (
                SELECT DISTINCT
                    REGEXP_EXTRACT(page_path, r'/([^/]+)/?$') as topic_slug
                FROM `{sanity_table}`
                WHERE timestamp >= TIMESTAMP_SUB(CURRENT_TIMESTAMP(), INTERVAL {days} DAY)
            )
            SELECT
                c.topic_slug,
                c.page_path as competitor_page,
                c.visits,
                'Missing on Sanity.io' as gap_type
            FROM competitor_topics c
            LEFT JOIN sanity_topics s ON LOWER(c.topic_slug) = LOWER(s.topic_slug)
            WHERE s.topic_slug IS NULL
            ORDER BY c.visits DESC
            LIMIT {limit}
            """

        else:
            return f"""ERROR: Unknown query_type '{query_type}'.
Available types:
- 'top_pages': All sites combined
- 'top_pages_sanity': Sanity.io only
- 'top_pages_enterprisecms': enterprisecms.org only
- 'top_pages_headlesscms': headlesscms.guides only
- 'trending': Pages with growing LLM traffic
- 'by_bot': Breakdown by LLM bot type
- 'content_gaps': Topics competitors have that Sanity doesn't"""

        df = client.query(query).to_dataframe()

        result = f"""
BIGQUERY LLM VISITS ANALYSIS
============================
Query type: {query_type}
Time period: Last {days} days
Results: {len(df)} rows

DATA:
{df.to_string(max_colwidth=80)}
"""

        # Add summary stats
        if 'visits' in df.columns:
            result += f"\n\nSUMMARY:"
            result += f"\n- Total visits: {df['visits'].sum():,}"
            result += f"\n- Average per page: {df['visits'].mean():.1f}"
            result += f"\n- Median: {df['visits'].median():.1f}"

        return result

    except Exception as e:
        import traceback
        traceback.print_exc()
        return f"ERROR querying BigQuery: {str(e)}"


@tool
def bigquery_custom_query(sql: str) -> str:
    """
    Run a custom SQL query against BigQuery LLM visit tables.

    Available tables (use full names in query):
    - data-platform-302218.searchconsole.llm-visits2 (Sanity.io)
    - indexing-api-471516.enterprisecms.llm-logs (enterprisecms.org)
    - indexing-api-471516.headlesscms.llm-logs (headlesscms.guides)

    IMPORTANT: Use backticks around table names with hyphens.
    Example: SELECT * FROM `data-platform-302218.searchconsole.llm-visits2` LIMIT 10

    Use bigquery_describe_table first to understand the schema.
    """
    try:
        from google.cloud import bigquery
    except ImportError:
        return "ERROR: google-cloud-bigquery package required"

    bq_config = credentials['bigquery']

    # Safety checks
    sql_lower = sql.lower()
    if any(word in sql_lower for word in ['drop', 'delete', 'truncate', 'update', 'insert', 'create', 'alter']):
        return "ERROR: Only SELECT queries are allowed for safety."

    try:
        os.environ["GOOGLE_APPLICATION_CREDENTIALS"] = bq_config['credentials_file']
        client = bigquery.Client()

        # Add LIMIT if not present
        if 'limit' not in sql_lower:
            sql = sql.rstrip(';') + ' LIMIT 1000'

        df = client.query(sql).to_dataframe()

        result = f"""
BIGQUERY CUSTOM QUERY RESULTS
=============================
Query: {sql[:200]}{'...' if len(sql) > 200 else ''}
Rows returned: {len(df)}

DATA:
{df.to_string(max_colwidth=80)}
"""
        return result

    except Exception as e:
        import traceback
        traceback.print_exc()
        return f"ERROR executing query: {str(e)}"


# ============================================================
# Improved Sitemap Tool - More Thorough Content Detection
# ============================================================

@tool
def sanity_sitemap_lookup(query: str) -> str:
    """
    Comprehensive lookup of Sanity.io sitemap and existing content.
    Fetches ALL sitemaps and performs thorough matching including partial matches,
    related terms, and content categorization.

    Use this BEFORE recommending new content to verify it doesn't already exist.
    """
    sitemap_urls = [
        "https://www.sanity.io/sitemap.xml",
        "https://www.sanity.io/community-sitemap.xml",
        "https://www.sanity.io/main-sitemap.xml",
        "https://www.sanity.io/ui-sitemap.xml",
        "https://www.sanity.io/docs/sitemap.xml",
        "https://www.sanity.io/customerstories-sitemap.xml",
        "https://www.sanity.io/resources-sitemap.xml",
        "https://www.sanity.io/blog-sitemap.xml",
        "https://www.sanity.io/guides-sitemap.xml",
        "https://www.sanity.io/templates-sitemap.xml",
        "https://www.sanity.io/plugins-sitemap.xml",
        "https://www.sanity.io/exchange-sitemap.xml",
    ]

    all_urls = []
    sitemap_contents = {}

    for sitemap_url in sitemap_urls:
        try:
            response = requests.get(sitemap_url, timeout=30)
            if response.status_code == 200:
                root = ET.fromstring(response.content)

                namespaces = {'sm': 'http://www.sitemaps.org/schemas/sitemap/0.9'}

                # Check if this is a sitemap index
                sitemaps = root.findall('.//sm:sitemap/sm:loc', namespaces)
                if sitemaps:
                    for sitemap_loc in sitemaps[:10]:  # Increased limit
                        try:
                            child_response = requests.get(sitemap_loc.text, timeout=30)
                            if child_response.status_code == 200:
                                child_root = ET.fromstring(child_response.content)
                                urls = child_root.findall('.//sm:url/sm:loc', namespaces)
                                for url in urls:
                                    all_urls.append(url.text)
                                    sitemap_contents[url.text] = sitemap_url
                        except Exception:
                            continue
                else:
                    urls = root.findall('.//sm:url/sm:loc', namespaces)
                    for url in urls:
                        all_urls.append(url.text)
                        sitemap_contents[url.text] = sitemap_url
        except Exception:
            continue

    if not all_urls:
        return "Could not fetch sitemap. Error connecting to Sanity.io sitemaps."

    # Remove duplicates while preserving order
    all_urls = list(dict.fromkeys(all_urls))

    # Normalize query for matching
    query_lower = query.lower().strip()
    query_terms = query_lower.replace('-', ' ').replace('_', ' ').split()

    # Create variations of the query
    query_variations = [query_lower]
    query_variations.append(query_lower.replace(' ', '-'))
    query_variations.append(query_lower.replace(' ', '_'))
    query_variations.append(query_lower.replace('-', ''))
    query_variations.append(query_lower.replace('_', ''))

    # Common synonyms and related terms
    synonyms = {
        'content modeling': ['content-modeling', 'content model', 'schema', 'document types', 'content types'],
        'headless cms': ['headless-cms', 'api-first', 'decoupled'],
        'ai': ['artificial intelligence', 'machine learning', 'ml', 'llm', 'gpt', 'generative'],
        'structured content': ['structured-content', 'content structure'],
        'localization': ['localisation', 'i18n', 'internationalization', 'translation'],
    }

    # Add synonym variations
    for key, syns in synonyms.items():
        if key in query_lower or any(s in query_lower for s in syns):
            query_variations.extend(syns)
            query_variations.append(key)

    # Find matches with different levels of confidence
    exact_matches = []
    strong_matches = []
    partial_matches = []

    for url in all_urls:
        url_lower = url.lower()
        url_path = url_lower.replace('https://www.sanity.io/', '').replace('https://sanity.io/', '')

        # Exact match in URL
        if query_lower in url_path or query_lower.replace(' ', '-') in url_path:
            exact_matches.append(url)
        # All query terms present
        elif all(term in url_path for term in query_terms if len(term) > 2):
            strong_matches.append(url)
        # Any variation matches
        elif any(var in url_path for var in query_variations if len(var) > 3):
            partial_matches.append(url)
        # Any significant term matches
        elif any(term in url_path for term in query_terms if len(term) > 4):
            partial_matches.append(url)

    # Categorize all URLs
    categories = {
        'blog': [u for u in all_urls if '/blog/' in u],
        'docs': [u for u in all_urls if '/docs/' in u],
        'guides': [u for u in all_urls if '/guides/' in u or '/guide/' in u],
        'templates': [u for u in all_urls if '/templates/' in u or '/template/' in u],
        'plugins': [u for u in all_urls if '/plugins/' in u or '/plugin/' in u or '/exchange/' in u],
        'learn': [u for u in all_urls if '/learn/' in u],
        'resources': [u for u in all_urls if '/resources/' in u],
        'customer_stories': [u for u in all_urls if '/customers/' in u or '/case-stud' in u],
    }

    result = f"""
SANITY.IO SITEMAP ANALYSIS - COMPREHENSIVE
==========================================

Total URLs indexed: {len(all_urls)}

Content by category:
- Blog posts: {len(categories['blog'])}
- Documentation: {len(categories['docs'])}
- Guides: {len(categories['guides'])}
- Templates: {len(categories['templates'])}
- Plugins/Exchange: {len(categories['plugins'])}
- Learn: {len(categories['learn'])}
- Resources: {len(categories['resources'])}
- Customer Stories: {len(categories['customer_stories'])}

SEARCH RESULTS FOR: "{query}"
=============================

EXACT MATCHES ({len(exact_matches)}):
"""

    if exact_matches:
        for url in exact_matches[:15]:
            result += f"  ‚úì {url}\n"
    else:
        result += "  None found\n"

    result += f"\nSTRONG MATCHES ({len(strong_matches)}):\n"
    if strong_matches:
        for url in strong_matches[:15]:
            result += f"  ~ {url}\n"
    else:
        result += "  None found\n"

    result += f"\nPARTIAL/RELATED MATCHES ({len(partial_matches)}):\n"
    if partial_matches:
        for url in partial_matches[:20]:
            result += f"  ? {url}\n"
    else:
        result += "  None found\n"

    # Content gap assessment
    total_matches = len(exact_matches) + len(strong_matches)
    if total_matches == 0:
        result += f"\n‚ö†Ô∏è  POTENTIAL CONTENT GAP: No strong content found for '{query}'\n"
        result += "   This topic may be a good candidate for new content.\n"
    elif total_matches < 3:
        result += f"\nüìù LIMITED COVERAGE: Only {total_matches} pages found for '{query}'\n"
        result += "   Consider expanding content on this topic.\n"
    else:
        result += f"\n‚úÖ GOOD COVERAGE: {total_matches} relevant pages found for '{query}'\n"
        result += "   Review existing content before creating new.\n"

    return result


@tool
def sanity_content_audit(content_area: str) -> str:
    """
    Perform a content audit for a specific area of Sanity.io.

    content_area options:
    - 'ai': All AI/ML/LLM related content
    - 'integrations': Integration guides and docs
    - 'comparisons': Competitor comparison content
    - 'tutorials': Tutorial and how-to content
    - 'enterprise': Enterprise-focused content
    - 'developer': Developer experience content
    - 'all': Full content inventory

    Returns categorized URLs with freshness indicators where available.
    """
    # Fetch all URLs first
    sitemap_result = sanity_sitemap_lookup("audit")

    # Define search patterns for each area
    area_patterns = {
        'ai': ['ai', 'artificial-intelligence', 'machine-learning', 'ml', 'llm',
               'gpt', 'chatgpt', 'claude', 'generative', 'openai', 'anthropic',
               'vector', 'embedding', 'rag', 'retrieval'],
        'integrations': ['integration', 'integrate', 'connect', 'webhook',
                         'api', 'sdk', 'plugin', 'extension'],
        'comparisons': ['vs', 'versus', 'comparison', 'compare', 'alternative',
                        'contentful', 'strapi', 'wordpress', 'prismic', 'dato'],
        'tutorials': ['tutorial', 'how-to', 'guide', 'getting-started', 'learn',
                      'walkthrough', 'step-by-step', 'example'],
        'enterprise': ['enterprise', 'security', 'compliance', 'sso', 'saml',
                       'governance', 'audit', 'scale', 'migration'],
        'developer': ['developer', 'groq', 'schema', 'query', 'typescript',
                      'javascript', 'react', 'next', 'gatsby', 'nuxt', 'vue'],
    }

    all_urls = []
    sitemap_urls = [
        "https://www.sanity.io/sitemap.xml",
        "https://www.sanity.io/docs/sitemap.xml",
        "https://www.sanity.io/blog-sitemap.xml",
        "https://www.sanity.io/guides-sitemap.xml",
    ]

    for sitemap_url in sitemap_urls:
        try:
            response = requests.get(sitemap_url, timeout=30)
            if response.status_code == 200:
                root = ET.fromstring(response.content)
                namespaces = {'sm': 'http://www.sitemaps.org/schemas/sitemap/0.9'}

                # Handle sitemap index
                sitemaps = root.findall('.//sm:sitemap/sm:loc', namespaces)
                if sitemaps:
                    for sitemap_loc in sitemaps[:10]:
                        try:
                            child_response = requests.get(sitemap_loc.text, timeout=30)
                            if child_response.status_code == 200:
                                child_root = ET.fromstring(child_response.content)
                                for url_elem in child_root.findall('.//sm:url', namespaces):
                                    loc = url_elem.find('sm:loc', namespaces)
                                    lastmod = url_elem.find('sm:lastmod', namespaces)
                                    if loc is not None:
                                        all_urls.append({
                                            'url': loc.text,
                                            'lastmod': lastmod.text if lastmod is not None else None
                                        })
                        except Exception:
                            continue
                else:
                    for url_elem in root.findall('.//sm:url', namespaces):
                        loc = url_elem.find('sm:loc', namespaces)
                        lastmod = url_elem.find('sm:lastmod', namespaces)
                        if loc is not None:
                            all_urls.append({
                                'url': loc.text,
                                'lastmod': lastmod.text if lastmod is not None else None
                            })
        except Exception:
            continue

    # Filter by content area
    if content_area == 'all':
        patterns = []
        for p_list in area_patterns.values():
            patterns.extend(p_list)
    elif content_area in area_patterns:
        patterns = area_patterns[content_area]
    else:
        return f"ERROR: Unknown content_area '{content_area}'. Options: {list(area_patterns.keys()) + ['all']}"

    matching_urls = []
    for item in all_urls:
        url_lower = item['url'].lower()
        if any(p in url_lower for p in patterns):
            matching_urls.append(item)

    # Sort by lastmod if available
    matching_urls.sort(key=lambda x: x['lastmod'] or '', reverse=True)

    result = f"""
SANITY.IO CONTENT AUDIT: {content_area.upper()}
{'=' * 50}

Total URLs scanned: {len(all_urls)}
Matching URLs: {len(matching_urls)}

CONTENT INVENTORY:
"""

    # Categorize by freshness
    now = datetime.now()
    fresh = []  # Updated in last 3 months
    moderate = []  # Updated 3-12 months ago
    stale = []  # Updated > 12 months ago
    unknown = []  # No lastmod

    for item in matching_urls:
        if item['lastmod']:
            try:
                mod_date = datetime.fromisoformat(item['lastmod'].replace('Z', '+00:00'))
                age_days = (now - mod_date.replace(tzinfo=None)).days
                if age_days < 90:
                    fresh.append(item)
                elif age_days < 365:
                    moderate.append(item)
                else:
                    stale.append(item)
            except Exception:
                unknown.append(item)
        else:
            unknown.append(item)

    result += f"\nFRESH (< 3 months): {len(fresh)}\n"
    for item in fresh[:10]:
        result += f"  ‚úì [{item['lastmod'][:10] if item['lastmod'] else 'N/A'}] {item['url']}\n"

    result += f"\nMODERATE (3-12 months): {len(moderate)}\n"
    for item in moderate[:10]:
        result += f"  ~ [{item['lastmod'][:10] if item['lastmod'] else 'N/A'}] {item['url']}\n"

    result += f"\nSTALE (> 12 months): {len(stale)}\n"
    for item in stale[:10]:
        result += f"  ‚ö† [{item['lastmod'][:10] if item['lastmod'] else 'N/A'}] {item['url']}\n"

    result += f"\nUNKNOWN DATE: {len(unknown)}\n"
    for item in unknown[:10]:
        result += f"  ? {item['url']}\n"

    # Gap analysis for AI content
    if content_area == 'ai':
        expected_ai_topics = [
            'ai content generation', 'llm integration', 'vector search',
            'rag architecture', 'ai workflows', 'prompt engineering',
            'ai-powered cms', 'content ai', 'generative ai cms',
            'ai personalization', 'ai content strategy', 'ai seo'
        ]

        result += f"\n\nAI CONTENT GAP ANALYSIS:\n"
        result += "Expected AI topics and coverage:\n"

        for topic in expected_ai_topics:
            topic_found = any(topic.replace(' ', '-') in item['url'].lower() or
                            topic.replace(' ', '') in item['url'].lower()
                            for item in matching_urls)
            status = "‚úì Covered" if topic_found else "‚ö† MISSING"
            result += f"  {status}: {topic}\n"

    return result


# ============================================================
# Original Tools (keeping the working ones)
# ============================================================

@tool
def gsc_performance_lookup(query: str) -> str:
    """
    Fetch Google Search Console performance data for queries related to the topic.
    Returns impressions, clicks, CTR, and position data.
    """
    try:
        from google.oauth2 import service_account
        from googleapiclient.discovery import build
    except ImportError:
        return "ERROR: google-auth and google-api-python-client packages required."

    key_file = credentials['gsc']['key_file']
    site_url = credentials['gsc']['site_url']

    if not os.path.exists(key_file):
        return f"ERROR: GSC service account key file not found at {key_file}"

    try:
        gsc_credentials = service_account.Credentials.from_service_account_file(
            key_file,
            scopes=GSC_SCOPE
        )

        service = build(GSC_API_SERVICE_NAME, GSC_API_VERSION, credentials=gsc_credentials)

        end_date = datetime.now().strftime('%Y-%m-%d')
        start_date = (datetime.now() - timedelta(days=90)).strftime('%Y-%m-%d')

        request_body = {
            'startDate': start_date,
            'endDate': end_date,
            'dimensions': ['query'],
            'dimensionFilterGroups': [{
                'filters': [{
                    'dimension': 'query',
                    'operator': 'contains',
                    'expression': query
                }]
            }],
            'rowLimit': 50,
            'startRow': 0
        }

        response = service.searchanalytics().query(
            siteUrl=site_url,
            body=request_body
        ).execute()

        rows = response.get('rows', [])

        if not rows:
            return f"No GSC data found for queries containing '{query}'"

        result = f"""
GOOGLE SEARCH CONSOLE DATA
==========================
Site: {site_url}
Date range: {start_date} to {end_date}
Filter: queries containing "{query}"

Top Performing Queries:
"""

        for row in rows[:25]:
            query_text = row['keys'][0]
            clicks = row.get('clicks', 0)
            impressions = row.get('impressions', 0)
            ctr = row.get('ctr', 0) * 100
            position = row.get('position', 0)

            result += f"""
Query: {query_text}
  Clicks: {clicks} | Impressions: {impressions} | CTR: {ctr:.1f}% | Avg Position: {position:.1f}
"""

        total_clicks = sum(r.get('clicks', 0) for r in rows)
        total_impressions = sum(r.get('impressions', 0) for r in rows)
        avg_position = sum(r.get('position', 0) for r in rows) / len(rows) if rows else 0

        result += f"""
SUMMARY:
Total clicks: {total_clicks}
Total impressions: {total_impressions}
Average position: {avg_position:.1f}
Queries found: {len(rows)}
"""

        return result

    except Exception as e:
        import traceback
        traceback.print_exc()
        return f"ERROR fetching GSC data: {str(e)}"


@tool
def google_ads_keyword_ideas(query: str) -> str:
    """
    Fetch keyword ideas and search volume from Google Ads Keyword Planner API.
    Returns keyword suggestions with volume, competition, and bid estimates.
    """
    try:
        from google.ads.googleads.client import GoogleAdsClient
    except ImportError:
        return "ERROR: google-ads package required. Install with: pip install google-ads"

    ga_creds = credentials['google_ads']

    if ga_creds['developer_token'] == 'YOUR_DEVELOPER_TOKEN':
        return "ERROR: Google Ads API credentials not configured."

    try:
        yaml_content = f"""developer_token: {ga_creds['developer_token']}
client_id: {ga_creds['client_id']}
client_secret: {ga_creds['client_secret']}
refresh_token: {ga_creds['refresh_token']}
use_proto_plus: True
"""

        with open('google-ads.yaml', 'w') as f:
            f.write(yaml_content)

        client = GoogleAdsClient.load_from_storage('google-ads.yaml')
        customer_id = ga_creds['customer_id'].replace('-', '')

        keyword_plan_idea_service = client.get_service("KeywordPlanIdeaService")

        request = client.get_type("GenerateKeywordIdeasRequest")
        request.customer_id = customer_id
        request.language = "languageConstants/1000"
        request.geo_target_constants = ["geoTargetConstants/2840"]
        request.include_adult_keywords = False
        request.keyword_plan_network = client.enums.KeywordPlanNetworkEnum.GOOGLE_SEARCH

        request.keyword_seed.keywords.append(query)

        keyword_ideas = keyword_plan_idea_service.generate_keyword_ideas(request=request)

        result = f"""
GOOGLE ADS KEYWORD PLANNER DATA
===============================
Seed keyword: "{query}"

Keyword Ideas:
"""

        ideas_list = list(keyword_ideas)[:30]

        for idea in ideas_list:
            keyword = idea.text
            metrics = idea.keyword_idea_metrics

            avg_searches = metrics.avg_monthly_searches if metrics.avg_monthly_searches else 0
            competition = metrics.competition.name if metrics.competition else "UNKNOWN"
            low_bid = metrics.low_top_of_page_bid_micros / 1_000_000 if metrics.low_top_of_page_bid_micros else 0
            high_bid = metrics.high_top_of_page_bid_micros / 1_000_000 if metrics.high_top_of_page_bid_micros else 0

            result += f"""
Keyword: {keyword}
  Avg Monthly Searches: {avg_searches:,}
  Competition: {competition}
  Top of Page Bid: ${low_bid:.2f} - ${high_bid:.2f}
"""

        return result

    except Exception as e:
        import traceback
        traceback.print_exc()
        return f"ERROR fetching keyword data: {str(e)}"


@tool
def reddit_discussion_lookup(query: str) -> str:
    """
    Find relevant Reddit discussions and unanswered questions about the topic.
    Returns threads and comments from relevant subreddits.
    """
    try:
        import praw
    except ImportError:
        return "ERROR: praw package required. Install with: pip install praw"

    reddit_creds = credentials['reddit']

    if not reddit_creds['client_id'] or not reddit_creds['client_secret']:
        return "ERROR: Reddit API credentials not configured."

    try:
        reddit = praw.Reddit(
            client_id=reddit_creds['client_id'],
            client_secret=reddit_creds['client_secret'],
            user_agent=reddit_creds['user_agent'],
        )

        subreddits = [
            "webdev", "programming", "technology", "learnprogramming",
            "Wordpress", "frontend", "backend", "smallbusiness",
            "Entrepreneur", "content_marketing", "SEO", "Marketing",
            "FullStack", "nocode", "sideproject", "javascript",
            "reactjs", "nextjs", "jamstack", "headlessCMS", "cms",
            "MachineLearning", "artificial", "ChatGPT", "LocalLLaMA"
        ]

        all_posts = []
        all_comments = []
        pattern = rf"\b{re.escape(query)}\b"

        for subreddit_name in subreddits:
            try:
                subreddit = reddit.subreddit(subreddit_name)

                for submission in subreddit.search(query, limit=10):
                    if re.search(pattern, submission.title, re.IGNORECASE) or \
                       query.lower() in submission.title.lower() or \
                       'cms' in submission.title.lower() or \
                       'sanity' in submission.title.lower() or \
                       'headless' in submission.title.lower() or \
                       'ai' in submission.title.lower():

                        post_data = {
                            'title': submission.title,
                            'subreddit': subreddit_name,
                            'score': submission.score,
                            'num_comments': submission.num_comments,
                            'url': submission.url,
                            'permalink': f"https://reddit.com{submission.permalink}",
                            'created': datetime.fromtimestamp(submission.created_utc).strftime('%Y-%m-%d'),
                            'selftext': submission.selftext[:500] if submission.selftext else ''
                        }

                        if not any(p['permalink'] == post_data['permalink'] for p in all_posts):
                            all_posts.append(post_data)

                        try:
                            submission.comments.replace_more(limit=0)
                            for comment in submission.comments.list()[:5]:
                                if hasattr(comment, 'body'):
                                    all_comments.append({
                                        'thread_title': submission.title,
                                        'subreddit': subreddit_name,
                                        'comment': comment.body[:300],
                                        'score': comment.score
                                    })
                        except Exception:
                            pass

                time.sleep(1)

            except Exception:
                continue

        # Search for AI + CMS specific mentions
        try:
            for submission in reddit.subreddit("all").search(f"cms ai content {query}", limit=15):
                post_data = {
                    'title': submission.title,
                    'subreddit': submission.subreddit.display_name,
                    'score': submission.score,
                    'num_comments': submission.num_comments,
                    'url': submission.url,
                    'permalink': f"https://reddit.com{submission.permalink}",
                    'created': datetime.fromtimestamp(submission.created_utc).strftime('%Y-%m-%d'),
                    'selftext': submission.selftext[:500] if submission.selftext else ''
                }

                if not any(p['permalink'] == post_data['permalink'] for p in all_posts):
                    all_posts.append(post_data)
        except Exception:
            pass

        if not all_posts:
            return f"No Reddit discussions found for '{query}'"

        all_posts.sort(key=lambda x: x['score'] + x['num_comments'], reverse=True)

        result = f"""
REDDIT DISCUSSIONS
==================
Search query: "{query}"
Total relevant posts found: {len(all_posts)}
Total comments collected: {len(all_comments)}

Top Discussions by Engagement:
"""

        for post in all_posts[:15]:
            result += f"""
Title: {post['title']}
  Subreddit: r/{post['subreddit']}
  Score: {post['score']} | Comments: {post['num_comments']} | Date: {post['created']}
  URL: {post['permalink']}
"""
            if post['selftext']:
                preview = post['selftext'][:200].replace('\n', ' ')
                result += f"  Preview: {preview}...\n"

        questions = [p['title'] for p in all_posts if '?' in p['title']]
        if questions:
            result += "\nCommon Questions Asked:\n"
            for q in questions[:10]:
                result += f"  - {q}\n"

        if all_comments:
            result += "\nSample Comments (potential content ideas):\n"
            all_comments.sort(key=lambda x: x['score'], reverse=True)
            for comment in all_comments[:10]:
                preview = comment['comment'][:150].replace('\n', ' ')
                result += f"  - [r/{comment['subreddit']}] {preview}...\n"

        return result

    except Exception as e:
        import traceback
        traceback.print_exc()
        return f"ERROR fetching Reddit data: {str(e)}"


@tool
def openai_query_fanout(query: str) -> str:
    """
    Generate query variations using OpenAI, with special focus on AI + CMS topics.
    """
    api_key = credentials['openai']['api_key']

    if not api_key:
        return generate_query_variations_local(query)

    try:
        import openai
        client = openai.OpenAI(api_key=api_key)

        prompt = f"""Given the topic/keyword "{query}" in the context of content management systems, AI, and web development, generate:

1. 10 likely questions a developer or marketer might ask an AI assistant about this topic
2. 5 comparison queries (e.g., "X vs Y")
3. 5 "how to" queries
4. 5 AI-specific queries (how AI/LLMs relate to this topic)
5. 5 "best" or "top X" queries (important for AEO/featured snippets)

Focus on queries that would be relevant to someone:
- Evaluating or using a headless CMS
- Exploring AI integration with content management
- Making enterprise content decisions

Format each query on its own line, grouped by category."""

        response = client.chat.completions.create(
            model="gpt-4o",
            messages=[{"role": "user", "content": prompt}],
            max_tokens=1200,
            temperature=0.7
        )

        result = f"""
LLM QUERY FANOUT
================
Base topic: "{query}"

{response.choices[0].message.content}
"""
        return result

    except Exception:
        return generate_query_variations_local(query)


def generate_query_variations_local(query: str) -> str:
    """Fallback query variation generator with AI focus."""

    patterns = {
        "questions": [
            f"What is {query}?",
            f"How does {query} work in a headless CMS?",
            f"Why use {query} for content management?",
            f"When should I use {query}?",
            f"What are the benefits of {query}?",
        ],
        "comparisons": [
            f"{query} vs Contentful",
            f"{query} vs Strapi",
            f"Sanity {query} vs WordPress",
            f"Best {query} solution for enterprise",
        ],
        "how_to": [
            f"How to implement {query} in Sanity",
            f"How to set up {query} with Next.js",
            f"How to configure {query} for headless CMS",
            f"How to migrate {query} to Sanity",
        ],
        "ai_queries": [
            f"How to use AI with {query}",
            f"AI-powered {query} for CMS",
            f"LLM integration with {query}",
            f"Automating {query} with AI",
            f"ChatGPT for {query} in content management",
        ],
        "top_x_lists": [
            f"Top 10 {query} tools",
            f"Best {query} practices 2025",
            f"Top {query} solutions for enterprise",
            f"Best {query} examples",
            f"Leading {query} platforms compared",
        ]
    }

    result = f"""
LLM QUERY FANOUT (Local Generation)
===================================
Base topic: "{query}"

Likely Questions:
"""
    for q in patterns["questions"]:
        result += f"  - {q}\n"

    result += "\nComparison Queries:\n"
    for q in patterns["comparisons"]:
        result += f"  - {q}\n"

    result += "\nHow-To Queries:\n"
    for q in patterns["how_to"]:
        result += f"  - {q}\n"

    result += "\nAI-Related Queries (KEY FOCUS):\n"
    for q in patterns["ai_queries"]:
        result += f"  - {q}\n"

    result += "\nTop X / Best Lists (AEO Important):\n"
    for q in patterns["top_x_lists"]:
        result += f"  - {q}\n"

    return result


@tool
def top_google_search_pages(query: str) -> str:
    """
    Identify current top-ranking Google search pages for the query.
    Provides analysis framework and competitor content gaps.
    """
    search_url = f"https://www.google.com/search?q={query.replace(' ', '+')}"

    result = f"""
TOP GOOGLE SEARCH PAGES ANALYSIS
================================
Query: "{query}"

Search URL: {search_url}

KEY COMPETITOR DOMAINS TO CHECK:
1. Contentful.com - Major competitor
2. Strapi.io - Open source competitor
3. Prismic.io - Mid-market competitor
4. DatoCMS.com - Enterprise competitor
5. Hygraph.com (formerly GraphCMS)
6. Storyblok.com - Visual editing competitor
7. Builder.io - No-code competitor

CONTENT FORMAT ANALYSIS CHECKLIST:
‚ñ° Does Sanity have a page specifically for "{query}"?
‚ñ° What format do top results use? (guide, comparison, tutorial, list)
‚ñ° Is there a featured snippet? What type?
‚ñ° Are there "People also ask" questions?
‚ñ° What schema markup do competitors use?

COMPETITOR CONTENT GAP INDICATORS:
- If competitors have dedicated pages and Sanity doesn't = HIGH PRIORITY GAP
- If no one has good content = OPPORTUNITY TO OWN THE TOPIC
- If Sanity has old/thin content vs comprehensive competitor content = UPDATE NEEDED

AEO SIGNALS TO CHECK:
- Do AI assistants cite any sources for this query?
- What domains get cited in ChatGPT/Claude responses?
- Is there a clear, quotable definition available?
"""

    return result


@tool
def top_aeo_pages(query: str) -> str:
    """
    Identify AEO (Answer Engine Optimization) opportunities with focus on:
    - Top X lists and rankings
    - Definitional content
    - Comparison content
    """

    result = f"""
AEO (ANSWER ENGINE OPTIMIZATION) ANALYSIS
==========================================
Query: "{query}"

‚≠ê HIGH-VALUE AEO CONTENT TYPES:

1. TOP X LISTS (Very Important for LLM Citation)
   Examples for "{query}":
   - "Top 10 {query} platforms"
   - "Best {query} tools for 2025"
   - "Top 5 {query} use cases"
   - "Leading {query} solutions compared"

   WHY: LLMs love citing ranked lists. They're easy to parse
   and provide clear, structured answers.

2. DEFINITIONAL CONTENT
   - "What is {query}?"
   - Clear, quotable 1-2 sentence definitions
   - Structured explanations with headers

3. COMPARISON TABLES
   - "{query} vs [competitor]" content
   - Feature comparison matrices
   - Pricing comparison tables

4. HOW-TO CONTENT WITH STEPS
   - Numbered step-by-step guides
   - Clear prerequisites and outcomes
   - Code examples for technical topics

SANITY.IO AEO RECOMMENDATIONS FOR "{query}":

Content Structure Requirements:
‚úì First paragraph must contain a clear, standalone definition
‚úì Use H2/H3 headers that match common questions
‚úì Include a comparison table if relevant
‚úì Add numbered lists for steps/rankings
‚úì Update date must be within last 90 days for LLM trust

Format Priority Order:
1. Create a "Top 10 {query}" style article
2. Create a definitive "What is {query}" guide
3. Create comparison content vs competitors
4. Create a step-by-step tutorial

FRESHNESS REQUIREMENTS (Critical for AEO):
- LLMs strongly prefer content updated in last 3 months
- Add "Last updated: [date]" prominently
- Review and refresh quarterly minimum

ENTITY GROUNDING:
- Mention specific tools, companies, standards by name
- Link to authoritative sources
- Be explicit about Sanity.io's approach to {query}
"""

    return result


@tool
def fetch_webpage_content(url: str) -> str:
    """
    Fetch and extract main text content from a webpage.
    Useful for analyzing competitor content depth and structure.
    """
    try:
        from bs4 import BeautifulSoup
    except ImportError:
        return "ERROR: beautifulsoup4 package required."

    try:
        headers = {
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'
        }

        response = requests.get(url, headers=headers, timeout=30)
        response.raise_for_status()

        soup = BeautifulSoup(response.content, 'html.parser')

        for element in soup(["script", "style", "nav", "footer", "header", "aside"]):
            element.decompose()

        title = soup.title.string.strip() if soup.title and soup.title.string else "No title found"

        meta_desc = ""
        meta_tag = soup.find("meta", attrs={"name": "description"})
        if meta_tag and meta_tag.get("content"):
            meta_desc = meta_tag["content"]

        headings = []
        for level in range(1, 5):
            for heading in soup.find_all(f'h{level}'):
                text = heading.get_text(strip=True)
                if text:
                    headings.append(f"{'  ' * (level-1)}H{level}: {text}")

        main_content = (
            soup.find('main') or
            soup.find('article') or
            soup.find('div', {'role': 'main'}) or
            soup.find('div', class_=re.compile(r'content|post|article|docs', re.I))
        )

        if main_content:
            text = main_content.get_text(separator='\n', strip=True)
        else:
            text = soup.get_text(separator='\n', strip=True)

        lines = [line.strip() for line in text.splitlines() if line.strip()]
        text = '\n'.join(lines)

        if len(text) > 10000:
            text = text[:10000] + "\n\n[Content truncated...]"

        word_count = len(text.split())
        has_code = bool(soup.find('code') or soup.find('pre'))
        num_images = len(soup.find_all('img'))
        num_lists = len(soup.find_all(['ul', 'ol']))
        num_tables = len(soup.find_all('table'))

        result = f"""
WEBPAGE CONTENT ANALYSIS
========================
URL: {url}

TITLE: {title}

META DESCRIPTION: {meta_desc[:200] if meta_desc else "None"}

HEADING STRUCTURE ({len(headings)} headings):
{chr(10).join(headings[:40]) if headings else "No headings found"}

CONTENT METRICS:
- Word count: ~{word_count}
- Code blocks: {'Yes' if has_code else 'No'}
- Images: {num_images}
- Lists: {num_lists}
- Tables: {num_tables}

MAIN CONTENT:
{text[:6000]}
"""

        return result

    except requests.exceptions.RequestException as e:
        return f"ERROR fetching URL {url}: {str(e)}"
    except Exception as e:
        return f"ERROR parsing content from {url}: {str(e)}"


@tool
def fetch_and_compare_urls(urls: str) -> str:
    """
    Fetch and compare content from multiple URLs side by side.
    Input: comma-separated URLs (max 5).
    Essential for competitor gap analysis.
    """
    url_list = [u.strip() for u in urls.split(',') if u.strip()]

    if not url_list:
        return "ERROR: No valid URLs provided."

    if len(url_list) > 5:
        url_list = url_list[:5]

    results = []

    for url in url_list:
        content = fetch_webpage_content(url)

        word_count = 0
        has_code = False
        heading_count = 0

        if "Word count:" in content:
            try:
                word_count = int(re.search(r'Word count: ~?(\d+)', content).group(1))
            except:
                pass

        if "Code blocks: Yes" in content:
            has_code = True

        if "headings)" in content:
            try:
                heading_count = int(re.search(r'\((\d+) headings\)', content).group(1))
            except:
                pass

        results.append({
            'url': url,
            'word_count': word_count,
            'has_code': has_code,
            'heading_count': heading_count,
            'full_analysis': content
        })

        time.sleep(1)

    output = f"""
MULTI-URL CONTENT COMPARISON
============================
URLs analyzed: {len(results)}

QUICK COMPARISON:
{'URL':<50} {'Words':<10} {'Headings':<10} {'Code'}
{'-'*80}
"""

    for r in results:
        url_short = r['url'][:47] + '...' if len(r['url']) > 50 else r['url']
        output += f"{url_short:<50} {r['word_count']:<10} {r['heading_count']:<10} {'Yes' if r['has_code'] else 'No'}\n"

    output += "\n\nDETAILED ANALYSIS PER URL:\n"
    output += "=" * 80 + "\n"

    for r in results:
        output += f"\n{r['full_analysis']}\n"
        output += "-" * 80 + "\n"

    return output


@tool
def competitor_content_gaps(topic: str) -> str:
    """
    Analyze competitor content for a topic and identify gaps where Sanity.io
    is missing content that competitors have.

    Checks key competitor sites for content on the topic and compares to Sanity.io.
    """
    competitors = {
        'Contentful': f'https://www.contentful.com/api/search/?pageSize=50&query={topic.replace(" ", "+")}',
        'Strapi': f'https://strapi.io/search?q={topic.replace(" ", "+")}',
        'Prismic': f'https://prismic.io/search?q={topic.replace(" ", "+")}',
        'Storyblok': f'https://www.storyblok.com/search?q={topic.replace(" ", "+")}',
    }

    # Check if Sanity has content
    sanity_check = sanity_sitemap_lookup(topic)

    result = f"""
COMPETITOR CONTENT GAP ANALYSIS
===============================
Topic: "{topic}"

SANITY.IO COVERAGE:
{'-' * 40}
{sanity_check}

COMPETITOR PRESENCE (Manual verification needed):
{'-' * 40}
"""

    for name, url in competitors.items():
        result += f"\n{name}:\n"
        result += f"  Search URL: {url}\n"
        result += f"  Likely content URLs to check:\n"

        # Generate likely URLs based on common patterns
        topic_slug = topic.lower().replace(' ', '-')
        result += f"    - https://www.{name.lower()}.com/blog/{topic_slug}\n"
        result += f"    - https://www.{name.lower()}.com/docs/{topic_slug}\n"
        result += f"    - https://www.{name.lower()}.com/guides/{topic_slug}\n"

    result += f"""

GAP ANALYSIS CHECKLIST:
{'-' * 40}
‚ñ° Does Sanity have a dedicated page for "{topic}"?
‚ñ° Is Sanity's content as comprehensive as competitors?
‚ñ° Is Sanity's content more recently updated?
‚ñ° Does Sanity's content rank better in search?
‚ñ° Do AI assistants cite Sanity for this topic?

RECOMMENDED ACTIONS:
1. If no Sanity content exists: Create new content (HIGH PRIORITY)
2. If thin content exists: Expand and update
3. If competitors have better content: Analyze and improve
4. If Sanity is better: Optimize for AEO and discoverability
"""

    return result


# ============================================================
# LLM Configuration
# ============================================================

ANTHROPIC_API_KEY = credentials['anthropic']['api_key']

if not ANTHROPIC_API_KEY:
    print("WARNING: ANTHROPIC_API_KEY not set.")

from langchain_anthropic import ChatAnthropic

# Default: Sonnet 4.5 for most agents
default_llm = ChatAnthropic(
    model="claude-sonnet-4-5-20250929",
    temperature=0.7,
    anthropic_api_key=ANTHROPIC_API_KEY
)

# Smart LLM: Opus 4.5 for complex reasoning
smart_llm = ChatAnthropic(
    model="claude-opus-4-5-20251101",
    temperature=0.7,
    anthropic_api_key=ANTHROPIC_API_KEY
)

# Fast LLM: Haiku 4.5 for simple tasks
fast_llm = ChatAnthropic(
    model="claude-haiku-4-5-20251001",
    temperature=0.7,
    anthropic_api_key=ANTHROPIC_API_KEY
)


# ============================================================
# Agents - Refocused on Content Gaps + AI Topics
# ============================================================

data_analyst = Agent(
    role="Data Analyst",
    goal=(
        "Analyze LLM visit data, search performance, and competitor presence "
        "to identify TRUE CONTENT GAPS - topics where Sanity.io has NO content "
        "or significantly WEAKER content than competitors. Focus especially on "
        "AI + CMS topics which are rapidly growing."
    ),
    backstory=(
        "You specialize in finding content opportunities through data. You understand "
        "that the goal is NEW CONTENT creation, not optimizing existing content. "
        "You use BigQuery LLM visit data to understand what AI assistants are "
        "looking for, and cross-reference with Sanity's sitemap to find gaps."
    ),
    tools=[
        sanity_sitemap_lookup,
        sanity_content_audit,
        gsc_performance_lookup,
        google_ads_keyword_ideas,
        top_google_search_pages,
        fetch_webpage_content,
        fetch_and_compare_urls,
        bigquery_describe_table,
        bigquery_llm_visits,
        bigquery_custom_query,
        competitor_content_gaps,
    ],
    llm=default_llm,
    verbose=True
)


product_marketer = Agent(
    role="Product Marketing Manager",
    goal=(
        "Identify content gaps based on market conversations and competitor "
        "positioning. Focus on topics where potential customers are asking "
        "questions that Sanity.io doesn't answer - especially around AI + CMS "
        "integration and the 'Content Operating System' positioning."
    ),
    backstory=(
        "You understand the headless CMS market deeply and track competitor "
        "content strategies. You look for gaps where competitors have content "
        "that Sanity doesn't, or where neither has content but demand exists. "
        "You prioritize AI-related topics as a key differentiator."
    ),
    tools=[
        sanity_sitemap_lookup,
        sanity_content_audit,
        reddit_discussion_lookup,
        top_aeo_pages,
        fetch_webpage_content,
        fetch_and_compare_urls,
        competitor_content_gaps,
        bigquery_llm_visits,
    ],
    llm=default_llm,
    verbose=True
)


seo_specialist = Agent(
    role="SEO & AEO Content Specialist",
    goal=(
        "Identify search and AEO opportunities where Sanity.io is MISSING content "
        "that ranks well or gets cited by LLMs. Special focus on: "
        "1) Top X lists and rankings (high AEO value), "
        "2) AI + CMS topics (growing demand), "
        "3) Definitional content for emerging terms."
    ),
    backstory=(
        """You are an expert in both traditional SEO and Answer Engine Optimization (AEO).

KEY AEO INSIGHTS:
- TOP X LISTS are extremely valuable for LLM citation. Lists like "Top 10 headless CMS platforms"
  or "Best AI tools for content management" are frequently cited by ChatGPT, Claude, and Perplexity.
- FRESHNESS matters enormously - content updated in last 90 days is strongly preferred by LLMs.
- DEFINITIONAL CONTENT with clear, quotable first paragraphs gets cited frequently.
- COMPARISON TABLES are easily parseable by LLMs and often get cited.

Your job is NOT to optimize existing content. Your job is to find GAPS where:
1. Sanity.io has NO content on a topic with search/AEO demand
2. Competitors have content that Sanity doesn't
3. AI-related topics where no one has good content yet (opportunity to own)

Priority focus areas:
- AI content generation, AI workflows, LLM integration
- Top X lists for CMS features and comparisons
- Emerging content technology terms and concepts
"""
    ),
    tools=[
        gsc_performance_lookup,
        google_ads_keyword_ideas,
        openai_query_fanout,
        top_google_search_pages,
        top_aeo_pages,
        fetch_webpage_content,
        fetch_and_compare_urls,
        sanity_sitemap_lookup,
        sanity_content_audit,
        bigquery_llm_visits,
        competitor_content_gaps,
    ],
    llm=default_llm,
    verbose=True
)


work_reviewer = Agent(
    role="Content Gap Validator",
    goal=(
        "Validate that identified content gaps are REAL gaps - not content that "
        "already exists on Sanity.io. Cross-check every recommendation against "
        "the sitemap and existing content. Verify competitor claims."
    ),
    backstory=(
        "You are meticulous about verification. Previous runs have recommended "
        "content that already exists (like /content-modeling guides). Your job "
        "is to actually CHECK URLs and confirm gaps before they reach the final "
        "report. You search the sitemap thoroughly using multiple query variations."
    ),
    tools=[
        sanity_sitemap_lookup,
        sanity_content_audit,
        fetch_webpage_content,
        fetch_and_compare_urls,
        bigquery_llm_visits,
    ],
    llm=smart_llm,  # Opus for thorough validation
    verbose=True
)


narrative_governor = Agent(
    role="Narrative Governor",
    goal=(
        "Synthesize all findings into a prioritized action plan focused on "
        "NEW CONTENT creation. Remove any recommendations for content that "
        "already exists. Prioritize AI + CMS topics highly."
    ),
    backstory=(
        "You distill complex analyses into clear, actionable recommendations. "
        "You understand that the goal is identifying TRUE GAPS for new content, "
        "not optimization of existing content. You weight AI-related topics "
        "as high priority given market trends."
    ),
    llm=smart_llm,  # Opus for high-quality synthesis
    verbose=False
)


# ============================================================
# Tasks - Refocused on Content Gaps
# ============================================================

data_task = Task(
    description=(
        "Analyze data sources to find TRUE CONTENT GAPS where Sanity.io is missing content.\n\n"
        "CRITICAL FOCUS AREAS:\n"
        "1. AI + CMS topics (highest priority):\n"
        "   - AI content generation\n"
        "   - LLM integration with CMS\n"
        "   - AI-powered content workflows\n"
        "   - RAG (retrieval-augmented generation) and CMS\n"
        "   - Content for AI training/fine-tuning\n"
        "   - Vector search and semantic content\n\n"
        "2. Use BigQuery LLM visit data to see what AI assistants are fetching\n"
        "3. Cross-reference with Sanity sitemap to find gaps\n"
        "4. Check competitor sites for content Sanity doesn't have\n\n"
        "DO NOT recommend optimization of existing content.\n"
        "ONLY identify topics where Sanity has NO dedicated content."
    ),
    expected_output=(
        "A list of verified content gaps with:\n"
        "- Topic name and search volume/demand signals\n"
        "- Confirmation that NO Sanity content exists (sitemap check)\n"
        "- Evidence of demand (LLM visits, search volume, Reddit discussions)\n"
        "- Competitor presence (do they have content we don't?)\n"
        "- AI-relevance flag (is this an AI + CMS topic?)"
    ),
    agent=data_analyst
)


marketing_task = Task(
    description=(
        "Identify content gaps from a market and competitive perspective.\n\n"
        "FOCUS AREAS:\n"
        "1. AI + CMS market conversations:\n"
        "   - How are marketers/developers talking about AI in content?\n"
        "   - What AI questions remain unanswered?\n"
        "   - What AI use cases are competitors covering?\n\n"
        "2. Competitor content analysis:\n"
        "   - What topics do Contentful/Strapi/Prismic cover that Sanity doesn't?\n"
        "   - What guides/comparisons are competitors ranking for?\n"
        "   - Where are competitors getting cited by AI assistants?\n\n"
        "3. Community questions without good answers\n\n"
        "VERIFY: Before recommending a topic, CHECK sanity_sitemap_lookup to ensure\n"
        "Sanity doesn't already have content on that topic."
    ),
    expected_output=(
        "Competitive gap analysis with:\n"
        "- Topics competitors cover that Sanity doesn't\n"
        "- AI + CMS content opportunities\n"
        "- Community questions that need answers\n"
        "- For each: verification that Sanity lacks content"
    ),
    agent=product_marketer
)


seo_task = Task(
    description=(
        "Identify SEO and AEO content gaps with special focus on:\n\n"
        "1. TOP X LISTS (Critical for AEO):\n"
        "   - 'Top 10 headless CMS platforms'\n"
        "   - 'Best CMS for AI integration'\n"
        "   - 'Top content modeling tools'\n"
        "   - Ranking/comparison content that LLMs cite\n\n"
        "2. AI + CMS TOPICS (Emerging demand):\n"
        "   - AI content generation with CMS\n"
        "   - RAG architecture for content\n"
        "   - LLM-friendly content structure\n"
        "   - AI personalization\n\n"
        "3. DEFINITIONAL CONTENT:\n"
        "   - 'What is structured content?'\n"
        "   - 'What is a content operating system?'\n"
        "   - Clear, quotable definitions\n\n"
        "USE bigquery_llm_visits to see which pages AI bots actually visit.\n"
        "VERIFY each recommendation against sanity_sitemap_lookup.\n"
        "DO NOT recommend content that already exists."
    ),
    expected_output=(
        "Prioritized content gap list with:\n"
        "- Topic and content format (Top X list, guide, definition)\n"
        "- Search volume and AEO potential\n"
        "- Verification that content doesn't exist on Sanity\n"
        "- AI-relevance score (1-5)"
    ),
    agent=seo_specialist
)


review_task = Task(
    description=(
        "CRITICAL VALIDATION TASK:\n\n"
        "Review ALL recommendations from other agents and VERIFY each one:\n\n"
        "1. For each recommended content gap:\n"
        "   - Search sanity_sitemap_lookup with MULTIPLE query variations\n"
        "   - Check for partial matches, related content, similar topics\n"
        "   - Example: 'content modeling' should check 'content-modeling', 'schema',\n"
        "     'document types', 'content types', 'content model'\n\n"
        "2. REJECT recommendations where:\n"
        "   - Content already exists (even under different naming)\n"
        "   - Topic is too vague or duplicates another recommendation\n"
        "   - No clear evidence of demand\n\n"
        "3. VERIFY competitor claims:\n"
        "   - If we say 'Contentful has X content', verify it exists\n"
        "   - Use fetch_webpage_content on competitor URLs\n\n"
        "Previous runs missed existing content like /docs/content-modeling.\n"
        "BE THOROUGH in checking."
    ),
    expected_output=(
        "Validation report with:\n"
        "- VERIFIED GAPS: Topics confirmed to not exist on Sanity\n"
        "- REJECTED: Topics that actually have existing content (with URLs)\n"
        "- NEEDS REVIEW: Uncertain cases\n"
        "- Quality assessment of each agent's analysis"
    ),
    agent=work_reviewer,
    context=[data_task, marketing_task, seo_task]
)


governance_task = Task(
    description=(
        "Create the final prioritized action plan for NEW CONTENT creation.\n\n"
        "REQUIREMENTS:\n"
        "1. ONLY include gaps verified by the Work Reviewer\n"
        "2. EXCLUDE anything flagged as existing content\n"
        "3. PRIORITIZE AI + CMS topics highly (they're strategic)\n"
        "4. PRIORITIZE Top X lists (high AEO value)\n\n"
        "OUTPUT STRUCTURE:\n"
        "- Executive Summary (5 sentences max)\n"
        "- Top 15 Content Gaps, ranked by priority\n"
        "  - For each: Topic, Format, Rationale, Effort (S/M/L), AI-relevance\n"
        "- Quick Wins (can be published in < 1 week)\n"
        "- Strategic Investments (larger pieces)\n"
        "- AI Content Roadmap (specific AI + CMS pieces to create)\n"
        "- Competitor Gaps (content competitors have that we don't)"
    ),
    expected_output=(
        "Decision-ready content plan with:\n"
        "1. Executive summary\n"
        "2. Top 15 prioritized content gaps (verified)\n"
        "3. Quick wins list\n"
        "4. Strategic content investments\n"
        "5. AI + CMS content roadmap\n"
        "6. Competitor content gaps to close"
    ),
    agent=narrative_governor,
    context=[data_task, marketing_task, seo_task, review_task]
)


# ============================================================
# Crew Assembly - MEMORY DISABLED
# ============================================================

crew = Crew(
    agents=[
        data_analyst,
        product_marketer,
        seo_specialist,
        work_reviewer,
        narrative_governor
    ],
    tasks=[
        data_task,
        marketing_task,
        seo_task,
        review_task,
        governance_task
    ],
    process=Process.sequential,
    memory=False,  # DISABLED - Narrative Governor still works via task context
    verbose=True
)


# ============================================================
# Main Execution
# ============================================================

if __name__ == "__main__":
    print("=" * 60)
    print("CONTENT GAP DISCOVERY CREW v2")
    print("Focus: NEW CONTENT GAPS + AI TOPICS + COMPETITOR ANALYSIS")
    print("=" * 60)
    print()

    inputs = {
        "topic": "content management and AI",
        "focus_areas": [
            # AI + CMS (HIGHEST PRIORITY)
            "AI content generation CMS",
            "LLM integration headless CMS",
            "AI-powered content workflows",
            "RAG retrieval augmented generation CMS",
            "content for AI training",
            "vector search CMS",
            "AI personalization content",
            "generative AI content management",
            "ChatGPT CMS integration",
            "AI content strategy",

            # Top X Lists (HIGH AEO VALUE)
            "top headless CMS platforms",
            "best CMS for developers",
            "best CMS for AI",
            "top content modeling tools",
            "best enterprise CMS",

            # Definitional Content
            "what is structured content",
            "what is a content operating system",
            "what is headless CMS",
            "what is content modeling",
            "what is composable DXP",

            # Competitor Topics to Check
            "content localization",
            "content governance",
            "real-time collaboration CMS",
            "content versioning",
            "multi-tenant CMS",
        ]
    }

    print(f"Starting analysis for: {inputs['topic']}")
    print(f"Focus areas: {len(inputs['focus_areas'])} topics")
    print(f"Memory: DISABLED (using task context for Narrative Governor)")
    print()

    result = crew.kickoff()

    print()
    print("=" * 60)
    print("FINAL OUTPUT")
    print("=" * 60)
    print(result)